{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmPrWFxpOnNwPNLI42tsTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alikipanou/GeoTransformer/blob/main/multi_modal_hybrid_architecture_for_pedestrian_action_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PZebcUykiBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9c908f-d488-463a-dfa4-f3d62ba56164"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 128, 30, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import torch \n",
        "\n",
        "class MapEncoding(torch.nn.Module):\n",
        "  def __init__(self,in_channels):\n",
        "    super(MapEncoding, self).__init__()\n",
        "    modules = [torch.nn.Conv2d(in_channels, out_channels = 32, kernel_size = 3, stride = 4)]\n",
        "    modules.append(torch.nn.Conv2d(32, out_channels = 64, kernel_size = 3, stride = 2))\n",
        "    modules.append(torch.nn.Conv2d(64, out_channels = 128, kernel_size = 3, stride = 2))\n",
        "\n",
        "\n",
        "    self.net = torch.nn.Sequential(*modules)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)\n",
        "\n",
        "m = MapEncoding(20)\n",
        "d = torch.rand(50,20,500,200)\n",
        "o = m(d)\n",
        "o.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SceneEncoding(torch.nn.Module):\n",
        "  def __init__(self,in_channels):\n",
        "    super(SceneEncoding, self).__init__()\n",
        "    modules = [torch.nn.Conv2d(in_channels, out_channels = 64, kernel_size = 3, stride = 1)]\n",
        "    modules.append(torch.nn.Conv2d(64, out_channels = 64, kernel_size = 3, stride = 4))\n",
        "    modules.append(torch.nn.Conv2d(64, out_channels = 128, kernel_size = 3, stride = 2))\n",
        "    modules.append(torch.nn.Conv2d(128, out_channels = 256, kernel_size = 3, stride = 2))\n",
        "\n",
        "\n",
        "    self.net = torch.nn.Sequential(*modules)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)\n",
        "\n",
        "m = SceneEncoding(10)\n",
        "d = torch.rand(50,10,500,200)\n",
        "o = m(d)\n",
        "o.shape"
      ],
      "metadata": {
        "id": "VmJUG9krrQTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2ba366-5ca2-4202-9ead-c2dd722ecb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 256, 30, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VisualAttentionModule(torch.nn.Module):\n",
        "  def __init__(self,in_channels):\n",
        "   super(VisualAttentionModule, self).__init__() \n",
        "\n",
        "   modules = [torch.nn.Linear(in_channels, in_channels)]\n",
        "   modules.append(torch.nn.Softmax(dim = 1))\n",
        "\n",
        "   self.net = torch.nn.Sequential(*modules)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)\n",
        "\n",
        "d = torch.randn(50,20)\n",
        "v = VisualAttentionModule(20)\n",
        "v(d)"
      ],
      "metadata": {
        "id": "zCBUM_TYh5_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279ceed1-eaef-44cc-fc8f-3da8ad5e4197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0599, 0.0412, 0.0329, 0.1556, 0.0478, 0.0400, 0.0757, 0.0096, 0.0237,\n",
              "         0.0561, 0.0922, 0.0559, 0.0114, 0.0730, 0.0215, 0.0348, 0.0584, 0.0398,\n",
              "         0.0458, 0.0246],\n",
              "        [0.0465, 0.0406, 0.0286, 0.0538, 0.0702, 0.0605, 0.0432, 0.0484, 0.0257,\n",
              "         0.0357, 0.0272, 0.0189, 0.1780, 0.0231, 0.0401, 0.0613, 0.0497, 0.0356,\n",
              "         0.0532, 0.0597],\n",
              "        [0.1071, 0.0597, 0.0410, 0.0558, 0.0131, 0.0470, 0.0230, 0.0123, 0.0453,\n",
              "         0.1468, 0.0446, 0.0378, 0.0223, 0.0358, 0.0409, 0.0673, 0.0597, 0.0293,\n",
              "         0.0511, 0.0601],\n",
              "        [0.0791, 0.0461, 0.0348, 0.0564, 0.0339, 0.0609, 0.0343, 0.0400, 0.0319,\n",
              "         0.0561, 0.0380, 0.0185, 0.0409, 0.0312, 0.0299, 0.1575, 0.0732, 0.0471,\n",
              "         0.0358, 0.0545],\n",
              "        [0.0888, 0.0518, 0.0465, 0.0412, 0.0287, 0.0617, 0.0245, 0.0405, 0.0184,\n",
              "         0.0216, 0.0433, 0.0689, 0.0679, 0.0295, 0.0823, 0.0313, 0.0864, 0.0505,\n",
              "         0.0517, 0.0645],\n",
              "        [0.0534, 0.0968, 0.0604, 0.0490, 0.0516, 0.0638, 0.0123, 0.0631, 0.0198,\n",
              "         0.0198, 0.0272, 0.0425, 0.0433, 0.0226, 0.1233, 0.0682, 0.0268, 0.1055,\n",
              "         0.0227, 0.0280],\n",
              "        [0.0510, 0.0607, 0.0264, 0.0345, 0.0353, 0.0381, 0.0290, 0.0518, 0.0696,\n",
              "         0.0323, 0.0237, 0.0401, 0.0611, 0.0155, 0.0419, 0.0877, 0.0475, 0.0596,\n",
              "         0.0794, 0.1150],\n",
              "        [0.0460, 0.1272, 0.0817, 0.0310, 0.0529, 0.0783, 0.0203, 0.0510, 0.0128,\n",
              "         0.0551, 0.0731, 0.0378, 0.0109, 0.0510, 0.0556, 0.0235, 0.0612, 0.0431,\n",
              "         0.0479, 0.0396],\n",
              "        [0.0777, 0.0293, 0.0658, 0.0868, 0.0691, 0.0363, 0.0728, 0.0938, 0.0647,\n",
              "         0.0184, 0.0526, 0.0370, 0.0352, 0.0448, 0.0234, 0.0380, 0.0842, 0.0347,\n",
              "         0.0159, 0.0194],\n",
              "        [0.0384, 0.0412, 0.0929, 0.0174, 0.0915, 0.0916, 0.0441, 0.0417, 0.0211,\n",
              "         0.0774, 0.0752, 0.0430, 0.0825, 0.0161, 0.0690, 0.0130, 0.0416, 0.0315,\n",
              "         0.0605, 0.0102],\n",
              "        [0.0577, 0.0346, 0.0386, 0.0230, 0.0497, 0.0522, 0.0275, 0.0627, 0.0211,\n",
              "         0.0396, 0.0273, 0.0464, 0.1372, 0.0365, 0.0721, 0.0530, 0.0787, 0.0540,\n",
              "         0.0617, 0.0264],\n",
              "        [0.0563, 0.0499, 0.0437, 0.0494, 0.0404, 0.0468, 0.0440, 0.0422, 0.0170,\n",
              "         0.0386, 0.0391, 0.0530, 0.0729, 0.0329, 0.0209, 0.1789, 0.0294, 0.0649,\n",
              "         0.0421, 0.0376],\n",
              "        [0.0575, 0.0218, 0.0223, 0.1027, 0.0930, 0.0367, 0.0772, 0.0289, 0.0475,\n",
              "         0.0359, 0.0231, 0.0253, 0.1189, 0.0254, 0.0286, 0.0623, 0.0371, 0.0706,\n",
              "         0.0318, 0.0534],\n",
              "        [0.0254, 0.0714, 0.0353, 0.0273, 0.0591, 0.0080, 0.0302, 0.1357, 0.0323,\n",
              "         0.0448, 0.0136, 0.0440, 0.0228, 0.1246, 0.0488, 0.0193, 0.0875, 0.0837,\n",
              "         0.0288, 0.0576],\n",
              "        [0.0474, 0.0635, 0.0540, 0.0978, 0.0995, 0.0485, 0.0429, 0.0390, 0.0389,\n",
              "         0.0175, 0.0410, 0.0573, 0.0373, 0.0245, 0.0174, 0.0892, 0.0180, 0.0887,\n",
              "         0.0349, 0.0430],\n",
              "        [0.0340, 0.0539, 0.0445, 0.0624, 0.0952, 0.0236, 0.0474, 0.0972, 0.0546,\n",
              "         0.0417, 0.0343, 0.0131, 0.0964, 0.0670, 0.0370, 0.0401, 0.0541, 0.0284,\n",
              "         0.0288, 0.0465],\n",
              "        [0.0591, 0.0341, 0.0309, 0.0839, 0.0764, 0.0606, 0.0435, 0.0227, 0.0376,\n",
              "         0.0355, 0.0468, 0.0657, 0.0631, 0.0261, 0.0745, 0.0280, 0.0406, 0.0656,\n",
              "         0.0635, 0.0419],\n",
              "        [0.0682, 0.0460, 0.0286, 0.0491, 0.0422, 0.0125, 0.0369, 0.0347, 0.1049,\n",
              "         0.0781, 0.0087, 0.0269, 0.0203, 0.0642, 0.0370, 0.0710, 0.0389, 0.0898,\n",
              "         0.0171, 0.1249],\n",
              "        [0.0522, 0.0365, 0.0285, 0.0472, 0.0501, 0.0629, 0.0548, 0.0476, 0.0245,\n",
              "         0.0331, 0.0549, 0.0136, 0.1412, 0.0531, 0.0454, 0.0184, 0.1245, 0.0111,\n",
              "         0.0607, 0.0396],\n",
              "        [0.0276, 0.0086, 0.0262, 0.1110, 0.0665, 0.0244, 0.0253, 0.0233, 0.0511,\n",
              "         0.0265, 0.2091, 0.0236, 0.1632, 0.0085, 0.0130, 0.0710, 0.0050, 0.0251,\n",
              "         0.0496, 0.0412],\n",
              "        [0.0466, 0.0329, 0.0157, 0.0641, 0.0561, 0.0159, 0.0623, 0.0636, 0.0456,\n",
              "         0.0301, 0.0228, 0.0482, 0.0783, 0.0533, 0.0318, 0.0623, 0.0514, 0.0707,\n",
              "         0.0717, 0.0766],\n",
              "        [0.0817, 0.0361, 0.0618, 0.0578, 0.0613, 0.0143, 0.0314, 0.0818, 0.0308,\n",
              "         0.0229, 0.0251, 0.0746, 0.0519, 0.0509, 0.0311, 0.0809, 0.0338, 0.1302,\n",
              "         0.0226, 0.0188],\n",
              "        [0.0289, 0.0784, 0.0151, 0.0622, 0.0670, 0.0399, 0.0548, 0.0387, 0.0722,\n",
              "         0.0278, 0.0084, 0.0383, 0.0232, 0.0240, 0.0370, 0.1157, 0.0375, 0.1340,\n",
              "         0.0372, 0.0599],\n",
              "        [0.0669, 0.0386, 0.0282, 0.0627, 0.0320, 0.0195, 0.0353, 0.1104, 0.1456,\n",
              "         0.0179, 0.0165, 0.0201, 0.0900, 0.0266, 0.0401, 0.0623, 0.0576, 0.0439,\n",
              "         0.0210, 0.0648],\n",
              "        [0.1578, 0.0116, 0.1137, 0.0333, 0.0778, 0.0255, 0.0178, 0.0853, 0.0651,\n",
              "         0.0601, 0.0486, 0.0058, 0.0871, 0.0050, 0.0145, 0.0682, 0.0213, 0.0493,\n",
              "         0.0135, 0.0390],\n",
              "        [0.0689, 0.0629, 0.0231, 0.0170, 0.0222, 0.0514, 0.0324, 0.0457, 0.0160,\n",
              "         0.0141, 0.0112, 0.0749, 0.1190, 0.0239, 0.0847, 0.0473, 0.0917, 0.0363,\n",
              "         0.1118, 0.0455],\n",
              "        [0.0457, 0.0291, 0.0588, 0.0420, 0.0640, 0.0416, 0.0781, 0.0494, 0.0277,\n",
              "         0.0414, 0.1150, 0.0526, 0.0828, 0.0146, 0.0159, 0.0232, 0.0637, 0.0304,\n",
              "         0.0811, 0.0428],\n",
              "        [0.0297, 0.0817, 0.0136, 0.0302, 0.0142, 0.0612, 0.0246, 0.0444, 0.0196,\n",
              "         0.0305, 0.0075, 0.0485, 0.0378, 0.0357, 0.1676, 0.0661, 0.1435, 0.0969,\n",
              "         0.0224, 0.0240],\n",
              "        [0.0951, 0.0729, 0.0845, 0.0679, 0.0462, 0.0471, 0.0439, 0.0517, 0.0586,\n",
              "         0.0400, 0.0466, 0.0408, 0.0420, 0.0347, 0.0291, 0.0318, 0.0570, 0.0324,\n",
              "         0.0315, 0.0462],\n",
              "        [0.0345, 0.0515, 0.0272, 0.0761, 0.0430, 0.0463, 0.0415, 0.0835, 0.0681,\n",
              "         0.0246, 0.0323, 0.0351, 0.0417, 0.0730, 0.0474, 0.0774, 0.0920, 0.0390,\n",
              "         0.0244, 0.0414],\n",
              "        [0.0759, 0.0287, 0.0445, 0.1335, 0.0688, 0.0064, 0.0375, 0.0414, 0.0752,\n",
              "         0.0627, 0.0202, 0.0416, 0.0240, 0.1105, 0.0355, 0.0345, 0.0188, 0.0972,\n",
              "         0.0107, 0.0323],\n",
              "        [0.0835, 0.0242, 0.0292, 0.0971, 0.0377, 0.0488, 0.0482, 0.0166, 0.0334,\n",
              "         0.0753, 0.0728, 0.0478, 0.0655, 0.0263, 0.0293, 0.0463, 0.0480, 0.0388,\n",
              "         0.0759, 0.0553],\n",
              "        [0.0734, 0.0251, 0.0682, 0.0458, 0.1254, 0.0162, 0.0687, 0.0312, 0.0670,\n",
              "         0.0399, 0.0382, 0.0785, 0.0768, 0.0307, 0.0203, 0.0407, 0.0162, 0.0674,\n",
              "         0.0467, 0.0233],\n",
              "        [0.1683, 0.0422, 0.0879, 0.0146, 0.0250, 0.0188, 0.0198, 0.0987, 0.0358,\n",
              "         0.0470, 0.0190, 0.0297, 0.0292, 0.0133, 0.0167, 0.0727, 0.0505, 0.0880,\n",
              "         0.0272, 0.0953],\n",
              "        [0.0215, 0.0750, 0.0154, 0.0407, 0.0169, 0.0501, 0.0538, 0.0341, 0.0163,\n",
              "         0.0254, 0.0387, 0.0352, 0.0659, 0.0937, 0.0465, 0.0460, 0.1990, 0.0077,\n",
              "         0.0951, 0.0232],\n",
              "        [0.0293, 0.0318, 0.0344, 0.0405, 0.0994, 0.0706, 0.0237, 0.1143, 0.0196,\n",
              "         0.0180, 0.0645, 0.0226, 0.1137, 0.0301, 0.0695, 0.0494, 0.0571, 0.0382,\n",
              "         0.0503, 0.0231],\n",
              "        [0.0245, 0.1553, 0.0364, 0.0525, 0.0802, 0.0628, 0.0281, 0.0467, 0.0249,\n",
              "         0.0419, 0.0259, 0.0189, 0.0225, 0.0618, 0.0487, 0.0461, 0.0535, 0.0566,\n",
              "         0.0369, 0.0759],\n",
              "        [0.0936, 0.0470, 0.1044, 0.0193, 0.0326, 0.0343, 0.0435, 0.0377, 0.0174,\n",
              "         0.1520, 0.0699, 0.0561, 0.0134, 0.0434, 0.0202, 0.0202, 0.0704, 0.0384,\n",
              "         0.0471, 0.0392],\n",
              "        [0.0589, 0.0474, 0.0249, 0.0813, 0.0348, 0.0290, 0.1026, 0.0213, 0.0537,\n",
              "         0.0329, 0.0358, 0.0713, 0.0298, 0.0889, 0.0100, 0.0555, 0.0758, 0.0215,\n",
              "         0.0680, 0.0567],\n",
              "        [0.0699, 0.0830, 0.0778, 0.0230, 0.0612, 0.0152, 0.0574, 0.0326, 0.0101,\n",
              "         0.1176, 0.0197, 0.0631, 0.0246, 0.1037, 0.0303, 0.0202, 0.0361, 0.0678,\n",
              "         0.0437, 0.0430],\n",
              "        [0.0957, 0.0207, 0.0306, 0.0614, 0.0392, 0.0607, 0.0457, 0.0275, 0.0502,\n",
              "         0.0378, 0.0852, 0.0515, 0.0288, 0.0206, 0.0195, 0.0562, 0.0502, 0.0388,\n",
              "         0.0747, 0.1050],\n",
              "        [0.0190, 0.0908, 0.0322, 0.0368, 0.0278, 0.0742, 0.0253, 0.0302, 0.0184,\n",
              "         0.0506, 0.0932, 0.0608, 0.0370, 0.0565, 0.0706, 0.0464, 0.0639, 0.0178,\n",
              "         0.1100, 0.0384],\n",
              "        [0.0831, 0.0263, 0.0391, 0.0623, 0.0320, 0.0538, 0.0326, 0.0385, 0.0533,\n",
              "         0.1017, 0.0724, 0.0191, 0.0522, 0.0321, 0.0188, 0.1060, 0.0361, 0.0248,\n",
              "         0.0425, 0.0734],\n",
              "        [0.0511, 0.0556, 0.0483, 0.0830, 0.0985, 0.0323, 0.0357, 0.0281, 0.0363,\n",
              "         0.0736, 0.0330, 0.0433, 0.0226, 0.0898, 0.0527, 0.0324, 0.0348, 0.0850,\n",
              "         0.0315, 0.0324],\n",
              "        [0.0726, 0.1115, 0.0915, 0.0274, 0.0552, 0.0356, 0.0355, 0.0687, 0.0302,\n",
              "         0.0456, 0.0172, 0.0395, 0.0608, 0.0470, 0.0476, 0.0252, 0.0789, 0.0351,\n",
              "         0.0416, 0.0333],\n",
              "        [0.0157, 0.1280, 0.0262, 0.0819, 0.0352, 0.0437, 0.0301, 0.0408, 0.0403,\n",
              "         0.0262, 0.0358, 0.0127, 0.0165, 0.1805, 0.0335, 0.0303, 0.1628, 0.0095,\n",
              "         0.0239, 0.0261],\n",
              "        [0.0449, 0.0309, 0.0176, 0.0724, 0.0350, 0.0366, 0.0300, 0.0148, 0.1671,\n",
              "         0.0374, 0.0422, 0.0541, 0.0167, 0.0110, 0.0225, 0.0790, 0.0162, 0.0786,\n",
              "         0.0581, 0.1351],\n",
              "        [0.0704, 0.0179, 0.0245, 0.0897, 0.0587, 0.0623, 0.0691, 0.0296, 0.0461,\n",
              "         0.0195, 0.0696, 0.0346, 0.0814, 0.0232, 0.0214, 0.0606, 0.0593, 0.0449,\n",
              "         0.0515, 0.0656],\n",
              "        [0.0463, 0.0223, 0.0247, 0.0573, 0.0813, 0.0400, 0.0493, 0.0386, 0.0728,\n",
              "         0.0183, 0.0448, 0.1233, 0.0406, 0.0217, 0.0336, 0.0631, 0.0239, 0.0941,\n",
              "         0.0643, 0.0396],\n",
              "        [0.0339, 0.0500, 0.0306, 0.0664, 0.0898, 0.0168, 0.0564, 0.0856, 0.0399,\n",
              "         0.0326, 0.0230, 0.0234, 0.1243, 0.0542, 0.0661, 0.0154, 0.0572, 0.0587,\n",
              "         0.0291, 0.0465]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicsAttentionModule(torch.nn.Module):\n",
        "  def __init__(self,length,hidden_size):\n",
        "    super(DynamicsAttentionModule, self).__init__()\n",
        "    \n",
        "    self.Wa = torch.nn.Parameter(torch.randn(hidden_size,hidden_size))\n",
        "    self.Wa.requires_grad = True\n",
        "\n",
        "    self.Wc = torch.nn.Parameter(torch.randn(hidden_size,2*hidden_size))\n",
        "    self.Wc.requires_grad = True\n",
        "\n",
        "    self.t = length\n",
        "    self.hid_size = hidden_size\n",
        "\n",
        "  def forward(self,x):\n",
        "    # x --> (B,hid_size,t)\n",
        "    t = torch.matmul(self.Wa,x) \n",
        "    x_trans = x.permute(0,2,1)\n",
        "\n",
        "    q = torch.sigmoid(torch.matmul(x_trans,t))\n",
        "    tens = torch.zeros(x.shape[0],self.t,1,self.t)\n",
        "    tens[:,:,0,:] = q\n",
        "    tens = tens.repeat(1,1,x.shape[1],1)\n",
        "\n",
        "    X = torch.zeros(x.shape[0],1,self.hid_size,self.t)\n",
        "    X[:,0,:,:] = x\n",
        "    X = X.repeat(1,self.t,1,1)\n",
        "\n",
        "    weights = torch.mul(tens,X)\n",
        "    c = torch.sum(weights,3)  #(B,t,hid_size)\n",
        "    c = c.permute(0,2,1)  #(B,hid_size,t)\n",
        "\n",
        "    cat = torch.cat((c,x),1) #(Β,2*hid_size,t)\n",
        "\n",
        "    dam = torch.tanh(torch.matmul(self.Wc,cat) )\n",
        "\n",
        "    return dam\n",
        "\n",
        "d = torch.rand((50,500,10))\n",
        "model =  DynamicsAttentionModule(10,500)\n",
        "out = model(d)\n"
      ],
      "metadata": {
        "id": "0nwyqQw29e16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class HybridModel(torch.nn.Module):\n",
        "  def __init__(self,map_channels,scene_channels,ped_size,ev_size,t):\n",
        "    super(HybridModel, self).__init__()\n",
        "\n",
        "    self.map_encoding_module = MapEncoding(map_channels)\n",
        "    self.scene_encoding_module = SceneEncoding(scene_channels)\n",
        "    self.vam = VisualAttentionModule(512)\n",
        "    self.dam = DynamicsAttentionModule(t,512)\n",
        "\n",
        "    self.c = torch.nn.Conv2d(256+128, out_channels = 512, kernel_size = 3, stride = 1)\n",
        "    self.l = torch.nn.Linear(243200, 512)\n",
        "\n",
        "    self.ped_lstm = torch.nn.LSTM(input_size = ped_size, hidden_size = 256, batch_first = True)\n",
        "    self.ev_lstm = torch.nn.LSTM(input_size = ev_size, hidden_size = 256, batch_first = True)\n",
        "\n",
        "\n",
        "  \n",
        "  def forward(self,map,scene,ped_motion,ev_motion):\n",
        "    out_map = self.map_encoding_module(map)\n",
        "    out_scene = self.scene_encoding_module(scene)\n",
        "\n",
        "    #print(out_map.shape)\n",
        "    #print(out_scene.shape)\n",
        "\n",
        "    οut_map_scene = torch.cat((out_map,out_scene),1)\n",
        "\n",
        "    out_conv = self.c(οut_map_scene)\n",
        "    out_flat = torch.flatten(out_conv,start_dim = 1)\n",
        "    out_reduced = self.l(out_flat)\n",
        "\n",
        "    out_vam = self.vam(out_reduced)\n",
        "\n",
        "    (out_lstm1,hn_cn) = self.ped_lstm(ped_motion)\n",
        "    (out_lstm2,hn_cn) = self.ev_lstm(ev_motion)\n",
        "\n",
        "    print(out_lstm1.shape)\n",
        "\n",
        "\n",
        "m  = HybridModel(15,15,6,2,10)\n",
        "d1 = torch.rand(10,15,350,450)\n",
        "d2 = torch.rand(10,15,350,450)\n",
        "d3 = torch.randn(10,10,6)\n",
        "d4 = torch.randn(10,10,2)\n",
        "\n",
        "\n",
        "m(d1,d2,d3,d4)"
      ],
      "metadata": {
        "id": "6H1LIqwhB4-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843f5c07-70b6-4ff9-a561-88a050a8f14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 10, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch module\n",
        "import torch\n",
        " \n",
        "# Define a 2D tensor\n",
        "tens = torch.tensor([[[1, 2, 3], [4, 5, 6], [47, 38, 29]],\n",
        "                     [[7, 8, 9], [10, 11, 12], [5, 3, 1]],\n",
        "                     [[13, 14, 15], [16, 17, 18], [2, 4, 3]]])\n",
        "# display original tensor\n",
        "print(\"\\n Original Tensor: \\n\", tens)\n",
        " \n",
        "# find transpose of multi-dimension tensor\n",
        "tens_transpose = tens.permute(0,2,1)\n",
        "#tens2 = torch.split(tens,1,dim = 0)\n",
        "tens2 = torch.zeros(3,3,1,3)\n",
        "tens2[:,:,0,:] = tens\n",
        "tens2 = tens2.repeat(1,1,3,1)\n",
        "t1 = torch.randn(50,10,500,10)\n",
        "\n",
        "print(tens.repeat(1,2,1))\n",
        "t2 = torch.randn(50,500,10)\n",
        "print(tens2.shape)\n",
        "print(t2.shape)\n",
        "t = torch.mul(t1[:,1,:,:],t2)\n",
        "# display final result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWOvKpOc_Oe_",
        "outputId": "b78133fd-32ca-488c-ea3a-4059f2ebabb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Original Tensor: \n",
            " tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6],\n",
            "         [47, 38, 29]],\n",
            "\n",
            "        [[ 7,  8,  9],\n",
            "         [10, 11, 12],\n",
            "         [ 5,  3,  1]],\n",
            "\n",
            "        [[13, 14, 15],\n",
            "         [16, 17, 18],\n",
            "         [ 2,  4,  3]]])\n",
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6],\n",
            "         [47, 38, 29],\n",
            "         [ 1,  2,  3],\n",
            "         [ 4,  5,  6],\n",
            "         [47, 38, 29]],\n",
            "\n",
            "        [[ 7,  8,  9],\n",
            "         [10, 11, 12],\n",
            "         [ 5,  3,  1],\n",
            "         [ 7,  8,  9],\n",
            "         [10, 11, 12],\n",
            "         [ 5,  3,  1]],\n",
            "\n",
            "        [[13, 14, 15],\n",
            "         [16, 17, 18],\n",
            "         [ 2,  4,  3],\n",
            "         [13, 14, 15],\n",
            "         [16, 17, 18],\n",
            "         [ 2,  4,  3]]])\n",
            "torch.Size([3, 3, 3, 3])\n",
            "torch.Size([50, 500, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B  = 10 \n",
        "t = 4\n",
        "x = torch.rand(B,20,t)\n",
        "c = torch.rand(B,20,t)\n",
        "\n",
        "torch.cat((x,c),1).shape\n",
        "\n",
        "\n",
        "\n",
        "X = torch.zeros(B,1,20,t)\n",
        "X[:,0,:,:] = x\n",
        "x = X.repeat(1,t,1,1)\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxZWPVNgoWHR",
        "outputId": "b7b33712-a367-400d-d62a-2ac93f0eb616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.7450, 0.2218, 0.8524, 0.8619],\n",
            "          [0.9971, 0.0833, 0.6543, 0.5368],\n",
            "          [0.2814, 0.1802, 0.0624, 0.7050],\n",
            "          ...,\n",
            "          [0.7421, 0.0260, 0.1662, 0.5063],\n",
            "          [0.7589, 0.4727, 0.6168, 0.8142],\n",
            "          [0.7658, 0.1250, 0.3186, 0.5399]],\n",
            "\n",
            "         [[0.7450, 0.2218, 0.8524, 0.8619],\n",
            "          [0.9971, 0.0833, 0.6543, 0.5368],\n",
            "          [0.2814, 0.1802, 0.0624, 0.7050],\n",
            "          ...,\n",
            "          [0.7421, 0.0260, 0.1662, 0.5063],\n",
            "          [0.7589, 0.4727, 0.6168, 0.8142],\n",
            "          [0.7658, 0.1250, 0.3186, 0.5399]],\n",
            "\n",
            "         [[0.7450, 0.2218, 0.8524, 0.8619],\n",
            "          [0.9971, 0.0833, 0.6543, 0.5368],\n",
            "          [0.2814, 0.1802, 0.0624, 0.7050],\n",
            "          ...,\n",
            "          [0.7421, 0.0260, 0.1662, 0.5063],\n",
            "          [0.7589, 0.4727, 0.6168, 0.8142],\n",
            "          [0.7658, 0.1250, 0.3186, 0.5399]],\n",
            "\n",
            "         [[0.7450, 0.2218, 0.8524, 0.8619],\n",
            "          [0.9971, 0.0833, 0.6543, 0.5368],\n",
            "          [0.2814, 0.1802, 0.0624, 0.7050],\n",
            "          ...,\n",
            "          [0.7421, 0.0260, 0.1662, 0.5063],\n",
            "          [0.7589, 0.4727, 0.6168, 0.8142],\n",
            "          [0.7658, 0.1250, 0.3186, 0.5399]]],\n",
            "\n",
            "\n",
            "        [[[0.7883, 0.5534, 0.1003, 0.6316],\n",
            "          [0.3366, 0.7162, 0.5697, 0.9428],\n",
            "          [0.0749, 0.6401, 0.9908, 0.2726],\n",
            "          ...,\n",
            "          [0.1408, 0.5339, 0.4497, 0.2013],\n",
            "          [0.8785, 0.6194, 0.3712, 0.2364],\n",
            "          [0.6136, 0.8659, 0.4439, 0.5212]],\n",
            "\n",
            "         [[0.7883, 0.5534, 0.1003, 0.6316],\n",
            "          [0.3366, 0.7162, 0.5697, 0.9428],\n",
            "          [0.0749, 0.6401, 0.9908, 0.2726],\n",
            "          ...,\n",
            "          [0.1408, 0.5339, 0.4497, 0.2013],\n",
            "          [0.8785, 0.6194, 0.3712, 0.2364],\n",
            "          [0.6136, 0.8659, 0.4439, 0.5212]],\n",
            "\n",
            "         [[0.7883, 0.5534, 0.1003, 0.6316],\n",
            "          [0.3366, 0.7162, 0.5697, 0.9428],\n",
            "          [0.0749, 0.6401, 0.9908, 0.2726],\n",
            "          ...,\n",
            "          [0.1408, 0.5339, 0.4497, 0.2013],\n",
            "          [0.8785, 0.6194, 0.3712, 0.2364],\n",
            "          [0.6136, 0.8659, 0.4439, 0.5212]],\n",
            "\n",
            "         [[0.7883, 0.5534, 0.1003, 0.6316],\n",
            "          [0.3366, 0.7162, 0.5697, 0.9428],\n",
            "          [0.0749, 0.6401, 0.9908, 0.2726],\n",
            "          ...,\n",
            "          [0.1408, 0.5339, 0.4497, 0.2013],\n",
            "          [0.8785, 0.6194, 0.3712, 0.2364],\n",
            "          [0.6136, 0.8659, 0.4439, 0.5212]]],\n",
            "\n",
            "\n",
            "        [[[0.5218, 0.0632, 0.5029, 0.9517],\n",
            "          [0.8487, 0.0707, 0.3875, 0.0880],\n",
            "          [0.2717, 0.3042, 0.5518, 0.4163],\n",
            "          ...,\n",
            "          [0.0415, 0.3882, 0.4467, 0.8428],\n",
            "          [0.9804, 0.4357, 0.1603, 0.1665],\n",
            "          [0.1786, 0.1733, 0.2035, 0.0593]],\n",
            "\n",
            "         [[0.5218, 0.0632, 0.5029, 0.9517],\n",
            "          [0.8487, 0.0707, 0.3875, 0.0880],\n",
            "          [0.2717, 0.3042, 0.5518, 0.4163],\n",
            "          ...,\n",
            "          [0.0415, 0.3882, 0.4467, 0.8428],\n",
            "          [0.9804, 0.4357, 0.1603, 0.1665],\n",
            "          [0.1786, 0.1733, 0.2035, 0.0593]],\n",
            "\n",
            "         [[0.5218, 0.0632, 0.5029, 0.9517],\n",
            "          [0.8487, 0.0707, 0.3875, 0.0880],\n",
            "          [0.2717, 0.3042, 0.5518, 0.4163],\n",
            "          ...,\n",
            "          [0.0415, 0.3882, 0.4467, 0.8428],\n",
            "          [0.9804, 0.4357, 0.1603, 0.1665],\n",
            "          [0.1786, 0.1733, 0.2035, 0.0593]],\n",
            "\n",
            "         [[0.5218, 0.0632, 0.5029, 0.9517],\n",
            "          [0.8487, 0.0707, 0.3875, 0.0880],\n",
            "          [0.2717, 0.3042, 0.5518, 0.4163],\n",
            "          ...,\n",
            "          [0.0415, 0.3882, 0.4467, 0.8428],\n",
            "          [0.9804, 0.4357, 0.1603, 0.1665],\n",
            "          [0.1786, 0.1733, 0.2035, 0.0593]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.8353, 0.3716, 0.4999, 0.5786],\n",
            "          [0.1073, 0.9877, 0.6835, 0.4916],\n",
            "          [0.0686, 0.2132, 0.4311, 0.8804],\n",
            "          ...,\n",
            "          [0.9776, 0.2523, 0.4696, 0.3496],\n",
            "          [0.2252, 0.6312, 0.7233, 0.8213],\n",
            "          [0.4426, 0.4644, 0.5402, 0.4545]],\n",
            "\n",
            "         [[0.8353, 0.3716, 0.4999, 0.5786],\n",
            "          [0.1073, 0.9877, 0.6835, 0.4916],\n",
            "          [0.0686, 0.2132, 0.4311, 0.8804],\n",
            "          ...,\n",
            "          [0.9776, 0.2523, 0.4696, 0.3496],\n",
            "          [0.2252, 0.6312, 0.7233, 0.8213],\n",
            "          [0.4426, 0.4644, 0.5402, 0.4545]],\n",
            "\n",
            "         [[0.8353, 0.3716, 0.4999, 0.5786],\n",
            "          [0.1073, 0.9877, 0.6835, 0.4916],\n",
            "          [0.0686, 0.2132, 0.4311, 0.8804],\n",
            "          ...,\n",
            "          [0.9776, 0.2523, 0.4696, 0.3496],\n",
            "          [0.2252, 0.6312, 0.7233, 0.8213],\n",
            "          [0.4426, 0.4644, 0.5402, 0.4545]],\n",
            "\n",
            "         [[0.8353, 0.3716, 0.4999, 0.5786],\n",
            "          [0.1073, 0.9877, 0.6835, 0.4916],\n",
            "          [0.0686, 0.2132, 0.4311, 0.8804],\n",
            "          ...,\n",
            "          [0.9776, 0.2523, 0.4696, 0.3496],\n",
            "          [0.2252, 0.6312, 0.7233, 0.8213],\n",
            "          [0.4426, 0.4644, 0.5402, 0.4545]]],\n",
            "\n",
            "\n",
            "        [[[0.7832, 0.0286, 0.1858, 0.1297],\n",
            "          [0.3721, 0.9976, 0.0432, 0.8099],\n",
            "          [0.4012, 0.0408, 0.6605, 0.3763],\n",
            "          ...,\n",
            "          [0.6994, 0.1419, 0.5511, 0.4397],\n",
            "          [0.4948, 0.0195, 0.5886, 0.9862],\n",
            "          [0.1597, 0.7977, 0.3982, 0.2977]],\n",
            "\n",
            "         [[0.7832, 0.0286, 0.1858, 0.1297],\n",
            "          [0.3721, 0.9976, 0.0432, 0.8099],\n",
            "          [0.4012, 0.0408, 0.6605, 0.3763],\n",
            "          ...,\n",
            "          [0.6994, 0.1419, 0.5511, 0.4397],\n",
            "          [0.4948, 0.0195, 0.5886, 0.9862],\n",
            "          [0.1597, 0.7977, 0.3982, 0.2977]],\n",
            "\n",
            "         [[0.7832, 0.0286, 0.1858, 0.1297],\n",
            "          [0.3721, 0.9976, 0.0432, 0.8099],\n",
            "          [0.4012, 0.0408, 0.6605, 0.3763],\n",
            "          ...,\n",
            "          [0.6994, 0.1419, 0.5511, 0.4397],\n",
            "          [0.4948, 0.0195, 0.5886, 0.9862],\n",
            "          [0.1597, 0.7977, 0.3982, 0.2977]],\n",
            "\n",
            "         [[0.7832, 0.0286, 0.1858, 0.1297],\n",
            "          [0.3721, 0.9976, 0.0432, 0.8099],\n",
            "          [0.4012, 0.0408, 0.6605, 0.3763],\n",
            "          ...,\n",
            "          [0.6994, 0.1419, 0.5511, 0.4397],\n",
            "          [0.4948, 0.0195, 0.5886, 0.9862],\n",
            "          [0.1597, 0.7977, 0.3982, 0.2977]]],\n",
            "\n",
            "\n",
            "        [[[0.0536, 0.6340, 0.5210, 0.3895],\n",
            "          [0.4860, 0.9359, 0.3000, 0.6064],\n",
            "          [0.9512, 0.3866, 0.0837, 0.5530],\n",
            "          ...,\n",
            "          [0.4719, 0.5451, 0.4759, 0.7325],\n",
            "          [0.8535, 0.9644, 0.6998, 0.3341],\n",
            "          [0.2236, 0.7781, 0.0823, 0.2905]],\n",
            "\n",
            "         [[0.0536, 0.6340, 0.5210, 0.3895],\n",
            "          [0.4860, 0.9359, 0.3000, 0.6064],\n",
            "          [0.9512, 0.3866, 0.0837, 0.5530],\n",
            "          ...,\n",
            "          [0.4719, 0.5451, 0.4759, 0.7325],\n",
            "          [0.8535, 0.9644, 0.6998, 0.3341],\n",
            "          [0.2236, 0.7781, 0.0823, 0.2905]],\n",
            "\n",
            "         [[0.0536, 0.6340, 0.5210, 0.3895],\n",
            "          [0.4860, 0.9359, 0.3000, 0.6064],\n",
            "          [0.9512, 0.3866, 0.0837, 0.5530],\n",
            "          ...,\n",
            "          [0.4719, 0.5451, 0.4759, 0.7325],\n",
            "          [0.8535, 0.9644, 0.6998, 0.3341],\n",
            "          [0.2236, 0.7781, 0.0823, 0.2905]],\n",
            "\n",
            "         [[0.0536, 0.6340, 0.5210, 0.3895],\n",
            "          [0.4860, 0.9359, 0.3000, 0.6064],\n",
            "          [0.9512, 0.3866, 0.0837, 0.5530],\n",
            "          ...,\n",
            "          [0.4719, 0.5451, 0.4759, 0.7325],\n",
            "          [0.8535, 0.9644, 0.6998, 0.3341],\n",
            "          [0.2236, 0.7781, 0.0823, 0.2905]]]])\n"
          ]
        }
      ]
    }
  ]
}